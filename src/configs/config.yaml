model:
  name: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
  
data:
  dataset: "GMSK8"
  max_length: 512
  train:
    path: "data/train.jsonl"
  test:
    path: "data/test.jsonl"


training:
  output_dir: "./tinyllama-finetuned"
  num_train_epochs: 1
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  learning_rate: 2e-5
  warmup_steps: 50
  logging_steps: 50
  eval_steps: 100
  save_steps: 100
  save_total_limit: 2
  bf16: true  # or fp16: true if your GPU supports it
  report_to: "none"